# TM BOT: PDF Analyzer

**Author:** Mary Nathalie Dela Cruz
**Date:** July 21, 2025

## 1. Project Overview

This project is a Streamlit-powered chat application designed to extract insights from PDF documents. It provides an end-to-end solution for users to upload a PDF, ask questions in natural language, and receive accurate, context-aware answers generated by a Large Language Model (LLM). The goal of this project is to build a production-ready Generative AI application that is robust, user-friendly, and showcases advanced RAG (Retrieval-Augmented Generation) techniques.

## 2. Running the Application

This is a step-by-step guide to set up and run the application.

### Prerequisites
* Python 3.10
* `pip` for package management
* An OpenAI API key

### Setup and Installation

1.  **Clone the Repository:**
    ```bash
    git clone [[repository_url]](https://github.com/MaryNathalie/TM_Bot.git)
    cd TM_Bot
    ```

2.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Start the Streamlit App:**
    Execute the following command from the root directory:
    ```bash
    streamlit run app.py
    ```

4.  **Access the Application:**
    Open your web browser and navigate to `http://localhost:8501`. You will be prompted to enter your OpenAI API key to authenticate. Once authenticated, you can upload a PDF and start interacting with the chatbot.


## 3. Design Decisions

This section details the architectural and technological choices made in building this application.

### Overall Architecture

The application is built around a sophisticated RAG pipeline, orchestrated using LangChain. Here is a step-by-step breakdown of the data flow:

1.  **User Authentication and Document Upload (`app.py`):** The user authenticates with their OpenAI API key, which is then used for all subsequent LLM and embedding model calls. The user then uploads a PDF document through the Streamlit interface.
2.  **Document Processing (`loader.py`):**
    * **GPU vs. CPU Detection:** The application first checks for the availability of a CUDA-enabled GPU.
    * **Docling for GPU-accelerated Processing:** If a GPU is available, the PDF is processed using the `docling` library to extract high-quality markdown text. This is the preferred method as `docling` can accurately extract text, tables, and other complex structures from PDFs. Table structure recognition is enabled to handle financial data accurately.
    * **PyPDF as a CPU Fallback:** If no GPU is available, the application falls back to the CPU-based `PyPDFLoader`.
    * **Caching:** To improve performance on subsequent runs with the same document, the markdown content extracted by `docling` is cached to a file.
3.  **Text Splitting (`loader.py`):** The extracted text (either markdown or plain text) is split into smaller, manageable chunks.
    * For markdown from `docling`, `MarkdownHeaderTextSplitter` is used to preserve the document's hierarchical structure, followed by `RecursiveCharacterTextSplitter` for any oversized chunks.
    * For plain text from `PyPDF`, `RecursiveCharacterTextSplitter` is used directly.
    * Chunking parameters (`CHUNK_SIZE` and `CHUNK_OVERLAP`) are defined in `src/constants.py`.
4.  **Vector Store Creation (`vectorstore.py`):** The document chunks are then embedded using OpenAI's embedding model and stored in an in-memory FAISS vector store. FAISS was chosen for its efficiency and because it satisfies the in-memory requirement of the exam.
5.  **Agent and Tool Creation (`chain.py`):** A router agent is created to intelligently select the appropriate tool for a given user query. Three specialized tools are defined:
    * `General_Information_Search`: A RAG chain for answering qualitative questions.
    * `Financial_Data_Search`: A RAG chain with a prompt specifically designed for extracting financial data.
    * `Document_Summarizer`: A summarization chain for providing high-level overviews of the document.
6.  **User Interaction and Response Generation (`app.py`):**
    * The user's query is passed to the router agent.
    * The agent selects the appropriate tool and invokes it with the user's query.
    * The selected tool generates a response, which is then displayed to the user in the Streamlit chat interface.
    * Conversational context is maintained using `ConversationBufferMemory`.

## 4. Prompt Engineering Strategies

My strategy involved creating specialized prompts for different tasks and using a router agent to select the appropriate one.

### General QA Prompt

```
### System:
You are a highly precise AI assistant designed for answering questions from a specific document. Your task is to use ONLY the provided context to answer the user's question.

### Instructions:
1.  Your answer must be based **strictly** on the information within the 'Context' section. Do not use any external knowledge or make assumptions.
2.  If the answer is not found in the provided context, you MUST state: "The provided context does not contain the answer to this question."
3.  Briefly **quote the key phrase** from the context that directly supports your answer to ensure it is verifiable.

### Context:
{context}

### Question:
{question}

### Answer:
```
**Reasoning:**
* **Role Prompting**: The prompt begins by assigning the LLM the role of a `highly precise AI assistant`.
* **Grounding and Guardrails**: The instructions `use ONLY the provided context` and `Do not use any external knowledge` prevents the model from hallucinating. Using `**strictly**` with markdown bolding adds strong emphasis.
* **Verifiability**: The requirement to `**quote the key phrase**` forces the model to cite its sources from the context.
* **Structure and Delimiters**: The use of `###` headers (e.g., `### System:`, `### Instructions:`) delineates the different parts of the prompt, making it easy for the model to parse.

### Financial QA Prompt
```
### System:
You are an expert financial analyst AI. Your task is to provide a precise answer to the user's question by synthesizing information from the provided financial report context.

### Instructions:
1.  Identify the key financial figures, dates, or terms in the user's question.
2.  Scan the provided context, **paying close attention to both narrative text and any tables**, to locate these specific data points.
3.  Formulate a clear, direct answer to the question using the extracted data.
4.  If the context does not contain the necessary information, state that clearly. **Do not make estimations.**

---
### Example:
**Context:** "Revenue from our cloud services reached $45.2 billion in the fiscal year 2023. The operating margin was 34%."
**Question:** "What was the cloud services revenue in 2023?"
**Answer:** "The cloud services revenue in fiscal year 2023 was $45.2 billion."
---

### Context:
{context}

### Question:
{question}

### Answer:
```
**Reasoning:**
* **Expert Persona**: The prompt assigns the role of an `expert financial analyst AI`.
* **Chain of Thought**: The numbered instructions (1. `Identify`, 2. `Scan`, 3. `Formulate`, 4. `State if not found`) guide the model through a logical reasoning process.
* **Emphasis and Specificity**: The instruction `**paying close attention to both narrative text and any tables**` is crucial because financial data is often found in tables, which can be easily missed. The `**` markdown adds emphasis.
* **One-Shot Learning**: The inclusion of a clear `### Example:` provides a concrete example of the expected input and output format. This helps the model to generate answers that are both accurate and well-formatted. The use of quotes (`"`) in the example text further clarifies the expected style.

### Summarization Prompt
```
### System:
You are an expert at summarizing text in relation to a specific question.

### Instructions:
Your task is to provide a concise, bullet-point summary of the key facts and insights from the 'Content' section that are **directly relevant** to the user's 'Question'.
- The summary should be **no more than 5 bullet points**.
- The summary should be focused and not include information from the content that is off-topic.
- Write for a **busy executive** who needs to understand the main takeaways quickly.

### Question:
{question}

### Content:
{text}

### Summary:
```
**Reasoning:**
* **Targeted Persona**: The instruction to `Write for a **busy executive**` guides the tone and style of the summary.
* **Constraints and Formatting**: The prompt provides clear constraints (`**no more than 5 bullet points**`) and formatting instructions (`bullet-point summary`). This ensures that the output is easy to read and digest.
* **Relevance Filtering**: The instruction to summarize facts that are `**directly relevant**` to the user's 'Question' is key to preventing the model from generating a generic summary of the entire document.

### Route Agent Prompt
```python
ChatPromptTemplate.from_messages([
    ("system", "You are an intelligent routing assistant. Your job is to analyze the user's question and choose the most appropriate tool to answer it."),
    ("human", "What are Microsoftâ€™s goals for AI in the coming years?"),
    ("ai", "General_Information_Search"),
    ("human", "How much did Microsoft earn in revenue and operating income in 2023?"),
    ("ai", "Financial_Data_Search"),
    MessagesPlaceholder(variable_name="chat_history", optional=True),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])
```
**Reasoning:**
* **Assistant Role with Examples**: The prompt sets up the `system` and `ai` roles with a clear objective and few-shot examples. This is highly effective for showing the router agent how to map a user's `human` query to the correct tool.
* **Conversational Context**: The inclusion of `MessagesPlaceholder(variable_name="chat_history")` allows the agent to consider the entire conversation history when deciding which tool to use.
* **Agent Scratchpad**: The `agent_scratchpad` placeholder allows the agent to keep track of its intermediate steps and reasoning (its own "chain of thought"), which is essential for more complex, multi-step operations.

## 5. Use Cases and Examples

TO FOLLOW

### General Questions

![General Question Example](general_question_image.png)

### Financial Questions

![Financial Question Example](financial_question_image.png)

### Summarization Tasks

![Summarization Example](summarization_image.png)

### Follow-Up Questions

![Follow-Up Question Example](follow_up_question_image.png)

## 6. Challenges Faced and Solutions Implemented

### LangChain and RAG Familiarity
* **Challenge:** I had a theoretical understanding of LangChain and RAG but had not yet built a production-level application using these technologies.
* **Solution:** I quickly ramped up by taking the "LangChain & Vector Databases in Production" course on ActiveLoop. This provided me with the foundational knowledge and practical skills needed to build this application.

### Document Processing
* **Challenge:** PDFs are notoriously difficult to parse, especially when they contain a mix of text, images, and tables. Simple text extraction often fails to capture the structure and content of tables accurately.
* **Solution:** I integrated the `docling` library, which is a powerful tool for converting PDFs to markdown while preserving their structure. I enabled the `do_table_structure` option to ensure that financial tables are correctly parsed.
* **Limitation:** `docling` can be slow, especially on CPU-only machines. I gathered the following performance data for processing the sample document:
    * Local laptop (CPU, 8 threads): ~769 seconds
    * A100 server (GPU, 256 threads): ~88 seconds
* **Solution:** To address this, I implemented a CPU fallback using the much faster `PyPDFLoader`. For GPU environments, I added a caching mechanism to store the processed markdown, so that documents only need to be processed once.

### In-Memory Vector Database
* **Challenge:** The exam suggested using an in-memory vector database. My initial learning was with a cloud-based solution.
* **Solution:** I researched and implemented FAISS, a popular and efficient in-memory vector database. It was straightforward to integrate with LangChain and met the exam's requirements.

### Handling Different Task Types
* **Challenge:** Users can ask different types of questions (e.g., general, financial, summarization), each requiring a different prompting strategy. Initially, I considered a UI-based approach for the user to select the task type, but this was not user-friendly.
* **Solution:** I implemented a router agent that automatically selects the appropriate tool based on the user's query. This is a more elegant and intelligent solution that improves the user experience.

### Maintaining Conversational Context
* **Challenge:** A stateless chatbot that cannot remember previous interactions is not very useful.
* **Solution:** I used LangChain's `ConversationBufferMemory` to store the chat history and feed it back into the router agent's prompt. This allows the bot to understand follow-up questions and maintain context.

### Slow Summarization
* **Challenge:** Summarizing the entire document at once would be very slow and could exceed the LLM's context window.
* **Solution:** I made the pragmatic decision to summarize only the first 20 chunks of the document. This provides a fast, high-level overview that is sufficient for most summarization requests.

## 7. Future Improvements
* **Advanced Memory Management:** Replace `ConversationBufferMemory` with `ConversationSummaryBufferMemory` or `ConversationBufferWindowMemory` to prevent the chat history from exceeding the model's token limit in long conversations.
* **SQL Tool for Tabular Data:** For documents with extensive tables, the markdown tables could be converted to pandas DataFrames and then loaded into a temporary SQL database. This would allow for the creation of an SQL tool that can answer complex queries about the tabular data.
* **Containerization:** The application could be containerized using Docker to ensure consistent deployment and scalability. A `Dockerfile` and `docker-compose.yml` would be created for this purpose.
* **More Robust CPU-based Processing:** The current `PyPDF`-based processing is simple. It could be improved by using regular expressions and sentence tokenizers to better handle the text structure.
* **Chat Session Management:** Implement a feature to save and load chat sessions, allowing users to resume their conversations at a later time.
* **Comprehensive Evaluation Framework:** Implement a more formal evaluation framework using metrics like RAGAs to quantitatively assess the performance of the RAG pipeline.
